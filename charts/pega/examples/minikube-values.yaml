---
global:
  # Enter your Kubernetes provider. Replace "YOUR_KUBERNETES_PROVIDER" with one of the following values:
  #   k8s - for a deployment using open-source Kubernetes
  #   openshift - for a deployment using Red Hat Openshift
  #   eks - for a deployment using Amazon EKS
  #   gke - for a deployment using Google Kubernetes Engine
  #   pks - for a deployment using Pivotal Container Service
  #   aks - for a deployment using Azure Kubernetes Service
  provider: "k8s"

  actions:
    # valid values are install, deploy, install-deploy
    # install - install the pega platform database.
    # deploy - deploy the full pega cluster
    # install-deploy - installation followed by full pega cluster deployment
    # upgrade - upgrades the pega platform to the build version.
    # upgrade-deploy - upgrades the pega platform and deploys the pega cluster on the upgraded database.
    execute: "deploy"
  # JDBC information to connect to the Pega database.
  # Pega must be installed to this database before deploying on Kubernetes.
  #
  # Examples for jdbc url and driver class:
  # For Oracle:
  #   url: jdbc:oracle:thin:@//YOUR_DB_HOST:1521/YOUR_DB_NAME
  #   driverClass: oracle.jdbc.OracleDriver
  # For Microsoft SQL Server:
  #   url: jdbc:sqlserver://YOUR_DB_HOST:1433;databaseName=YOUR_DB_NAME;selectMethod=cursor;sendStringParametersAsUnicode=false
  #   driverClass: com.microsoft.sqlserver.jdbc.SQLServerDriver
  # For IBM DB2 for LUW:
  #   url: jdbc:db2://YOUR_DB_HOST:50000/YOUR_DB_NAME:fullyMaterializeLobData=true;fullyMaterializeInputStreams=true;progressiveStreaming=2;useJDBC4ColumnNameAndLabelSemantics=2;
  #   driverClass: com.ibm.db2.jcc.DB2Driver
  # For IBM DB2 for z/OS:
  #   url: jdbc:db2://YOUR_DB_HOST:50000/YOUR_DB_NAME
  #   driverClass: com.ibm.db2.jcc.DB2Driver
  # For PostgreSQL:
  #   url: jdbc:postgresql://YOUR_DB_HOST:5432/YOUR_DB_NAME
  #   driverClass: org.postgresql.Driver
  # NOTE: These jdbc values provided are also considered for the upgrade source database details when upgrade/upgrade-deploy action is used.
  jdbc:
    url: "YOUR_JDBC_URL"
    driverClass: "YOUR_JDBC_DRIVER_CLASS"
    # Set the database type only for action = install/install-deploy/upgrade/upgrade-deploy. Valid values are: mssql, oracledate, udb, db2zos, postgres
    dbType: "YOUR_DATABASE_TYPE"
    # Set the uri to download the database driver for your database.
    driverUri: "YOUR_JDBC_DRIVER_URI"
    # Set your database username and password. These values will be obfuscated and stored in a secrets file.
    username: "YOUR_JDBC_USERNAME"
    password: "YOUR_JDBC_PASSWORD"
    # Set your connection properties that will be sent to our JDBC driver when establishing new connections,Format of the string must be [propertyName=property;]
    connectionProperties: ""
    # Set the rules and data schemas for your database. Additional schemas can be defined within Pega.
    rulesSchema: "YOUR_RULES_SCHEMA"
    dataSchema: "YOUR_DATA_SCHEMA"
    # If configured, set the customerdata schema for your database. Defaults to value of dataSchema if not provided.
    customerDataSchema: ""
  docker:
    registry:
      url: "YOUR_DOCKER_REGISTRY"
      # Provide your Docker registry username and password to access the docker image. These credentials will be
      # used for both the Pega Platform image and the Elasticsearch image.
      username: "YOUR_DOCKER_REGISTRY_USERNAME"
      password: "YOUR_DOCKER_REGISTRY_PASSWORD"

  tier:
    - name: "minikube"     
    # Enter the domain name to access web nodes via a load balancer.
    #  e.g. web.mypega.example.com
      service:
        domain: "YOUR_MINIKUBE_NODE_DOMAIN"
        port: 80
        targetPort: 8080
      nodeType: "Stream,BackgroundProcessing,WebUser,Search"
      # Enter the number of stream nodes for Kubernetes to deploy (minimum 2).
      replicas: 1
      # For an overview of setting CPU and memory resources, see https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/.
      # Enter the CPU request for each stream node (recommended 200m).
      cpuRequest: 200m
      # Enter the memory request for each stream node (recommended 6Gi).
      memRequest: "5Gi"
      # Enter the CPU limit for each stream node (recommended 2).
      cpuLimit: 2
      # Enter the memory limit for each stream node (recommended 8Gi).
      memLimit: "6Gi"
      # Enter any additional java options
      javaOpts: ""
      # Initial heap size for the jvm
      initialHeap: "4096m"
      # Maximum heap size for the jvm
      maxHeap: "4096m"
      # Set your Pega diagnostic credentials.
      pegaDiagnosticUser: ""
      pegaDiagnosticPassword: ""
      volumeClaimTemplate:
        resources:
          requests:
            storage: 5Gi

# Docker image information for the Pega docker image, containing the application server.
# To use this feature you MUST host the image using a private registry.
# See https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry
# Note: the imagePullPolicy is always for all images in this deployment, so pre-pulling images will not work.
docker:
  pega:
    image: "YOUR_PEGA_DEPLOY_IMAGE:TAG"

# Cassandra automatic deployment settings.
cassandra:
  # Set cassandra.enabled to true to automatically deploy the Cassandra sub-chart.
  # Set to false if dds.externalNodes is set, or if you do not need Cassandra in your Pega environment.
  enabled: false
  # Set any additional Cassandra parameters. These values will be used by Cassandra's helm chart.
  # See https://github.com/helm/charts/blob/master/incubator/cassandra/values.yaml
  persistence:
    enabled: true
  ## Minimum memory for development is 4GB and 2 CPU cores
  ## Minimum memory for production is 8GB and 4 CPU cores
  resources:
    requests:
      memory: "4Gi"
      cpu: 2
    limits:
      memory: "8Gi"
      cpu: 4

# DDS (external Cassandra) connection settings.
# These settings should only be modified if you are using a custom Cassandra deployment.
dds:
  # Enter an external node to use a custom external Cassandra deployment. If cassandra.enabled is set to true, leave dds.externalNodes blank.
  # If using an external node, cassandra.enabled should be set to false.
  # If dds.externalNodes is set and cassandra.enabled is set to true, Pega will connect to Cassandra using dds.externalNodes.
  externalNodes: ""
  # The port, username, and password should only be modified if supplying a custom external Cassandra node.
  port: "9042"
  username: "dnode_ext"
  password: "dnode_ext"

# Elasticsearch deployment settings.
# Note: This Elasticsearch deployment is used for Pega search, and is not the same Elasticsearch deployment used by the EFK stack.
# These search nodes will be deployed regardless of the Elasticsearch configuration above.
pegasearch:
  # Enter the docker image used to deploy Elasticsearch. This value will be ignored if using an external url.
  # Push the Elasticsearch image to your internal docker registry. This must be the same registry as the docker section above.
  image: "YOUR_ELASTICSEARCH_IMAGE:TAG"
  # Enter the Memory limit for each search node (recommended 4Gi).
  memLimit: "3Gi"

# Pega Installer settings
installer:
  image: "YOUR_INSTALLER_IMAGE:TAG"
  adminPassword: "ADMIN_PASSWORD"
